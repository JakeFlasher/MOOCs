{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966666666667\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cross validation with Sklearn\n",
    "\"\"\"\n",
    "#!/usr/bin/python\n",
    "\n",
    "\"\"\" this example borrows heavily from the example\n",
    "    shown on the sklearn documentation:\n",
    "\n",
    "    http://scikit-learn.org/stable/modules/cross_validation.html\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import cross_validation\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "labels = iris.target\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(iris.data, iris.target, \n",
    "                                                                                             test_size=0.4, random_state=0)\n",
    "\n",
    "###############################################################\n",
    "\n",
    "clf = SVC(kernel=\"linear\", C=1.)\n",
    "clf.fit(features_train, labels_train)\n",
    "\n",
    "print clf.score(features_test, labels_test)\n",
    "\n",
    "\n",
    "##############################################################\n",
    "def submitAcc():\n",
    "    return clf.score(features_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "kf = KFold(len(authors), 2) #(size of the data, number of folds)\n",
    "for train_indices, test_indices in kf:\n",
    "    #make training and testing datasets\n",
    "    feature_train = [word_data[ii] for ii in train_indices]\n",
    "    feature_test = [word_data[ii] for ii in test_indices]\n",
    "    author_train = [authors[ii] for ii in train_indices]\n",
    "    authors_test = [authors[ii] for ii in test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GridCV is a way of systematically working through multiple combinations of parameter tunes, cross-validating as it goes to \n",
    "determine which tune gives the best performance. The beauty is that it can work through many combinations in only a couple extra \n",
    "lines of code.\n",
    "\n",
    "Here's an example from the sklearn documentation, which can be found at:\n",
    "    http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "svr = svm.SVC()\n",
    "clf = grid_search.GridSearchCV(svr, parameters)\n",
    "clf.fit(iris.data, iris.target)\n",
    "\n",
    "Let's break this down line by line.\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]} \n",
    "A dictionary of the parameters, and the possible values you want to try for them. In this case, they're playing around with the \n",
    "kernel (possible choices are 'linear' and 'rbf'), and C (possible choices are 1 and 10).\n",
    "\n",
    "Then all the following (kernel, C) combinations are automatically generated: [('rbf', 1), ('rbf', 10), ('linear', 1), \n",
    "('linear', 10)]. Each is used to train an SVM, and the performance is then assessed using cross-validation.\n",
    "\n",
    "svr = svm.SVC() \n",
    "This looks kind of like creating a classifier, just like we've been doing since the first lesson. But note that the \"clf\" isn't \n",
    "made until the next line--this is just saying what kind of algorithm to use. Another way to think about this is that the \n",
    "\"classifier\" isn't just the algorithm in this case, it's algorithm plus parameter values. Note that there's no monkeying around \n",
    "with the kernel or C; all that is handled in the next line.\n",
    "\n",
    "clf = grid_search.GridSearchCV(svr, parameters) \n",
    "This is where the first bit of magic happens; the classifier is being created. We pass the algorithm (svr) and the dictionary of \n",
    "parameters to try (parameters) and it generates a grid of parameter combinations to try.\n",
    "\n",
    "clf.fit(iris.data, iris.target) \n",
    "And the second bit of magic. The fit function now tries all the parameter combinations, and returns a fitted classifier that's \n",
    "automatically tuned to the optimal parameter combination. You can now access the parameter values via clf.best_estimator_.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
