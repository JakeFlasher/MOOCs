{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this project, we will again try to identify the authors in a body of emails, this time using a decision tree. The starter \n",
    "code is in decision_tree/dt_author_id.py.\n",
    "\"\"\"\n",
    "#!/usr/bin/python\n",
    "\n",
    "import pickle\n",
    "import cPickle\n",
    "import numpy\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "\n",
    "\n",
    "def preprocess(words_file = \"word_data.pkl\", authors_file=\"email_authors.pkl\", perc=10):\n",
    "    \"\"\" \n",
    "        this function takes a pre-made list of email texts (by default word_data.pkl)\n",
    "        and the corresponding authors (by default email_authors.pkl) and performs\n",
    "        a number of preprocessing steps:\n",
    "            -- splits into training/testing sets (10% testing)\n",
    "            -- vectorizes into tfidf matrix\n",
    "            -- selects/keeps most helpful features\n",
    "\n",
    "        after this, the feaures and labels are put into numpy arrays, which play nice with sklearn functions\n",
    "\n",
    "        4 objects are returned:\n",
    "            -- training/testing features\n",
    "            -- training/testing labels\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ### the words (features) and authors (labels), already largely preprocessed\n",
    "    ### this preprocessing will be repeated in the text learning mini-project\n",
    "    authors_file_handler = open(authors_file, \"r\")\n",
    "    authors = pickle.load(authors_file_handler)\n",
    "    authors_file_handler.close()\n",
    "\n",
    "    words_file_handler = open(words_file, \"r\")\n",
    "    word_data = cPickle.load(words_file_handler)\n",
    "    words_file_handler.close()\n",
    "\n",
    "    ### test_size is the percentage of events assigned to the test set\n",
    "    ### (remainder go into training)\n",
    "    features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(word_data, authors, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "    ### text vectorization--go from strings to lists of numbers\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                                 stop_words='english')\n",
    "    features_train_transformed = vectorizer.fit_transform(features_train)\n",
    "    features_test_transformed  = vectorizer.transform(features_test)\n",
    "\n",
    "\n",
    "\n",
    "    ### feature selection, because text is super high dimensional and \n",
    "    ### can be really computationally chewy as a result\n",
    "    selector = SelectPercentile(f_classif, percentile=perc)\n",
    "    selector.fit(features_train_transformed, labels_train)\n",
    "    features_train_transformed = selector.transform(features_train_transformed).toarray()\n",
    "    features_test_transformed  = selector.transform(features_test_transformed).toarray()\n",
    "\n",
    "    ### info on the data\n",
    "    print \"no. of Chris training emails:\", sum(labels_train)\n",
    "    print \"no. of Sara training emails:\", len(labels_train)-sum(labels_train)\n",
    "    \n",
    "    return features_train_transformed, features_test_transformed, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "\"\"\" \n",
    "    This is the code to accompany the Lesson 3 (decision tree) mini-project.\n",
    "\n",
    "    Use a Decision Tree to identify emails from the Enron corpus by author:    \n",
    "    Sara has label 0\n",
    "    Chris has label 1\n",
    "\"\"\"\n",
    "#import sys\n",
    "#from time import time\n",
    "#sys.path.append(\"../tools/\")\n",
    "#from email_preprocess import preprocess\n",
    "\n",
    "\n",
    "### features_train and features_test are the features for the training\n",
    "### and testing datasets, respectively\n",
    "### labels_train and labels_test are the corresponding item labels\n",
    "features_train, features_test, labels_train, labels_test = preprocess(perc=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTree Accuracy: 0.966439135381\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Using the starter code in decision_tree/dt_author_id.py, get a decision tree up and running as a classifier, setting \n",
    "min_samples_split=40. It will probably take a while to train. What's the accuracy?\n",
    "\"\"\"\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf =  tree.DecisionTreeClassifier(min_samples_split=40)\n",
    "\n",
    "### train step\n",
    "clf.fit(features_train, labels_train)\n",
    "\n",
    "### use the trained classifier to predict labels for the test features\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "### calculate and return the accuracy on the test data\n",
    "accuracy = accuracy_score(pred, labels_test)\n",
    "\n",
    "print 'DTree Accuracy:', accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3785\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "You found in the SVM mini-project that the parameter tune can significantly speed up the training time of a machine learning \n",
    "algorithm. A general rule is that the parameters can tune the complexity of the algorithm, with more complex algorithms \n",
    "generally running more slowly.\n",
    "\n",
    "Another way to control the complexity of an algorithm is via the number of features that you use in training/testing. The more \n",
    "features the algorithm has available, the more potential there is for a complex fit. We will explore this in detail in the \n",
    "\"Feature Selection\" lesson, but you'll get a sneak preview now.\n",
    "\n",
    "What's the number of features in your data? (Hint: the data is organized into a numpy array where the number of rows is the \n",
    "number of data points and the number of columns is the number of features; so to extract this number, use a line of code \n",
    "like len(features_train[0]).)\n",
    "\"\"\"\n",
    "print len(features_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n",
      "379\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "go into ../tools/email_preprocess.py, and find the line of code that looks like this: \n",
    "\n",
    "selector = SelectPercentile(f_classif, percentile=10) \n",
    "\n",
    "Change percentile from 10 to 1, and rerun dt_author_id.py. Whatâ€™s the number of features now?\n",
    "\"\"\"\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = preprocess(perc=1)\n",
    "print len(features_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTree Accuracy: 0.967007963595\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "What's the accuracy of your decision tree when you use only 1% of your available features (i.e. percentile=1)?\n",
    "\"\"\"\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf =  tree.DecisionTreeClassifier(min_samples_split=40)\n",
    "\n",
    "### train step\n",
    "clf.fit(features_train, labels_train)\n",
    "\n",
    "### use the trained classifier to predict labels for the test features\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "### calculate and return the accuracy on the test data\n",
    "accuracy = accuracy_score(pred, labels_test)\n",
    "\n",
    "print 'DTree Accuracy:', accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
