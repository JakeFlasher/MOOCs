{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lesson 3: Decision Trees\n",
    "# URL: https://www.udacity.com/course/viewer#!/c-ud120/l-2258728540/m-2428648555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class_vis.py\n",
    "# ------------\n",
    "\n",
    "#!/usr/bin/python\n",
    "\n",
    "#from udacityplots import *\n",
    "import matplotlib \n",
    "matplotlib.use('agg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "\n",
    "#import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#plt.ioff()\n",
    "\n",
    "def prettyPicture(clf, X_test, y_test, fname='dtree.png'):\n",
    "    plt.clf()\n",
    "    x_min = 0.0; x_max = 1.0\n",
    "    y_min = 0.0; y_max = 1.0\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "    h = .01  # step size in the mesh\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=pl.cm.seismic)\n",
    "\n",
    "    # Plot also the test points\n",
    "    grade_sig = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==0]\n",
    "    bumpy_sig = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==0]\n",
    "    grade_bkg = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==1]\n",
    "    bumpy_bkg = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==1]\n",
    "\n",
    "    plt.scatter(grade_sig, bumpy_sig, color = \"b\", label=\"fast\")\n",
    "    plt.scatter(grade_bkg, bumpy_bkg, color = \"r\", label=\"slow\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"bumpiness\")\n",
    "    plt.ylabel(\"grade\")\n",
    "\n",
    "    plt.savefig(fname)\n",
    "    \n",
    "import base64\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "def output_image(name, format, bytes):\n",
    "    image_start = \"BEGIN_IMAGE_f9825uweof8jw9fj4r8\"\n",
    "    image_end = \"END_IMAGE_0238jfw08fjsiufhw8frs\"\n",
    "    data = {}\n",
    "    data['name'] = name\n",
    "    data['format'] = format\n",
    "    data['bytes'] = base64.encodestring(bytes)\n",
    "    print image_start+json.dumps(data)+image_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prep_terrain_data.py\n",
    "# --------------------\n",
    "\n",
    "#!/usr/bin/python\n",
    "import random\n",
    "\n",
    "\n",
    "def makeTerrainData(n_points=1000):\n",
    "###############################################################################\n",
    "### make the toy dataset\n",
    "    random.seed(42)\n",
    "    grade = [random.random() for ii in range(0,n_points)]\n",
    "    bumpy = [random.random() for ii in range(0,n_points)]\n",
    "    error = [random.random() for ii in range(0,n_points)]\n",
    "    y = [round(grade[ii]*bumpy[ii]+0.3+0.1*error[ii]) for ii in range(0,n_points)]\n",
    "    for ii in range(0, len(y)):\n",
    "        if grade[ii]>0.8 or bumpy[ii]>0.8:\n",
    "            y[ii] = 1.0\n",
    "\n",
    "### split into train/test sets\n",
    "    X = [[gg, ss] for gg, ss in zip(grade, bumpy)]\n",
    "    split = int(0.75*n_points)\n",
    "    X_train = X[0:split]\n",
    "    X_test  = X[split:]\n",
    "    y_train = y[0:split]\n",
    "    y_test  = y[split:]\n",
    "\n",
    "    grade_sig = [X_train[ii][0] for ii in range(0, len(X_train)) if y_train[ii]==0]\n",
    "    bumpy_sig = [X_train[ii][1] for ii in range(0, len(X_train)) if y_train[ii]==0]\n",
    "    grade_bkg = [X_train[ii][0] for ii in range(0, len(X_train)) if y_train[ii]==1]\n",
    "    bumpy_bkg = [X_train[ii][1] for ii in range(0, len(X_train)) if y_train[ii]==1]\n",
    "\n",
    "#    training_data = {\"fast\":{\"grade\":grade_sig, \"bumpiness\":bumpy_sig}\n",
    "#            , \"slow\":{\"grade\":grade_bkg, \"bumpiness\":bumpy_bkg}}\n",
    "\n",
    "\n",
    "    grade_sig = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==0]\n",
    "    bumpy_sig = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==0]\n",
    "    grade_bkg = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==1]\n",
    "    bumpy_bkg = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==1]\n",
    "\n",
    "    test_data = {\"fast\":{\"grade\":grade_sig, \"bumpiness\":bumpy_sig}\n",
    "            , \"slow\":{\"grade\":grade_bkg, \"bumpiness\":bumpy_bkg}}\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "#    return training_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classifyDT.py\n",
    "# -------------\n",
    "\n",
    "#!/usr/bin/python\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "def classify(features_train, labels_train, min_samples_split=2):   \n",
    "    ### import the sklearn module for Decision Trees\n",
    "    ### create classifier\n",
    "    ### fit the classifier on the training features and labels\n",
    "    ### return the fit classifier\n",
    "    \n",
    "    clf = tree.DecisionTreeClassifier(min_samples_split=min_samples_split)\n",
    "    clf.fit(features_train, labels_train)\n",
    "    return clf   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Output image at dtree.png>\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "\"\"\" Complete the code in classifyDT.py with the sklearn\n",
    "    Decision Tree classifier to classify the terrain data.\n",
    "    \n",
    "    The objective of this exercise is to recreate the decision \n",
    "    boundary found in the lesson video, and make a plot that\n",
    "    visually shows the decision boundary \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#from prep_terrain_data import makeTerrainData\n",
    "#from class_vis import prettyPicture, output_image\n",
    "#from classifyDT import classify\n",
    "\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = makeTerrainData()\n",
    "\n",
    "### the training data (features_train, labels_train) have both \"fast\" and \"slow\" points mixed\n",
    "### in together--separate them so we can give them different colors in the scatterplot,\n",
    "### and visually identify them\n",
    "grade_fast = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==0]\n",
    "bumpy_fast = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==0]\n",
    "grade_slow = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==1]\n",
    "bumpy_slow = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==1]\n",
    "\n",
    "clf = classify(features_train, labels_train)\n",
    "prettyPicture(clf, features_test, labels_test, fname='dtree.png')\n",
    "#output_image(\"test.png\", \"png\", open(\"test.png\", \"rb\").read())\n",
    "print(\"<Output image at dtree.png>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree acc: 0.908\n"
     ]
    }
   ],
   "source": [
    "def DTAccuracy(features_train, labels_train, features_test, labels_test):\n",
    "    \"\"\" compute the accuracy of your Decision Tree classifier \"\"\"\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    ### train step\n",
    "    clf = classify(features_train, labels_train)\n",
    "    \n",
    "    ### use the trained classifier to predict labels for the test features\n",
    "    pred = clf.predict(features_test)\n",
    "\n",
    "    ### calculate and return the accuracy on the test data\n",
    "    accuracy = accuracy_score(pred, labels_test)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "print 'Decision Tree acc:', (DTAccuracy(features_train, labels_train, features_test, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using min_sample=2: 0.908\n",
      "Accuracy using min_sample=50: 0.912\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now create 2 decision tree classifiers, one with min_samples_split=2 and one with min_samples_split=50\n",
    "compute the accuracies on the testing data and store the accuracy numbers to acc_min_samples_split_2 and\n",
    "acc_min_samples_split_50, respectively.\n",
    "\"\"\"\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = makeTerrainData()\n",
    "\n",
    "# min_samples_split=2\n",
    "clf = classify(features_train, labels_train, min_samples_split=2)\n",
    "pred = clf.predict(features_test)\n",
    "acc_2 = accuracy_score(pred, labels_test)\n",
    "print 'Accuracy using min_sample=2:', acc_2\n",
    "\n",
    "# min_samples_split=50\n",
    "clf = classify(features_train, labels_train, min_samples_split=50)\n",
    "pred = clf.predict(features_test)\n",
    "acc_50 = accuracy_score(pred, labels_test)\n",
    "print 'Accuracy using min_sample=50:', acc_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.918295834054\n"
     ]
    }
   ],
   "source": [
    "# Calculate Entropy for features\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def entropy_class(class_i):\n",
    "    count = Counter(class_i)\n",
    "    spi = 0\n",
    "    for feat in count:\n",
    "        pi = float(count[feat])/len(class_i)\n",
    "        spi += pi * math.log(pi, 2)\n",
    "    return -spi\n",
    "\n",
    "#class_i = ['slow', 'slow', 'fast', 'fast']\n",
    "class_i = ['slow', 'slow', 'fast']\n",
    "print entropy_class(class_i)\n",
    "#print 0.5 * math.log(0.5, 2) + 0.5 * math.log(0.5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
