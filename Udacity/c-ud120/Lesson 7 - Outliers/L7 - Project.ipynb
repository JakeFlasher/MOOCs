{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This project has two parts. In the first part, you will run a regression, and identify and remove the 10% of points that have \n",
    "the largest residual errors. Then you'll remove those outliers from the dataset and refit the regression, just like the strategy \n",
    "that Sebastian suggested in the lesson videos.\n",
    "\n",
    "In the second part, you will get acquainted with some of the outliers in the Enron finance data, and learn if/how to remove them.\n",
    "\n",
    "Sebastian described to us an algorithm for improving a regression, which you will implement in this project. You will work through\n",
    "it in the next few quizzes. To summarize, what you'll do is fit the regression on all training points discard the 10% of points \n",
    "that have the largest errors between the actual y values, and the regression-predicted y values refit on the remaining points.\n",
    "\n",
    "Start by running the starter code (outliers/outlier_removal_regression.py) and visualizing the points. A few outliers should \n",
    "clearly pop out. Deploy a linear regression, where net worth is the target and the feature being used to predict it is a person's \n",
    "age (remember to train on the training data!).\n",
    "\n",
    "The \"correct\" slope for the main body of data points is 6.25 (we know this because we used this value to generate the data); \n",
    "what slope does your regression have?\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "outlier_cleaner.py\n",
    "\"\"\"\n",
    "#!/usr/bin/python\n",
    "\n",
    "def outlierCleaner(predictions, ages, net_worths):\n",
    "    \"\"\"\n",
    "        Clean away the 10% of points that have the largest\n",
    "        residual errors (difference between the prediction\n",
    "        and the actual net worth).\n",
    "\n",
    "        Return a list of tuples named cleaned_data where \n",
    "        each tuple is of the form (age, net_worth, error).\n",
    "    \"\"\"\n",
    "    \n",
    "    cleaned_data = []\n",
    "\n",
    "    ### your code goes here\n",
    "\n",
    "    \n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your regression object doesn't exist, or isn't name reg\n",
      "can't make predictions to use in identifying outliers\n",
      "outlierCleaner() is returning an empty list, no refitting to be done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "outlier_removal_regression.py\n",
    "\"\"\"\n",
    "\n",
    "#!/usr/bin/python\n",
    "\n",
    "import random\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "#from outlier_cleaner import outlierCleaner\n",
    "\n",
    "### load up some practice data with outliers in it\n",
    "ages = pickle.load( open(\"practice_outliers_ages.pkl\", \"r\") )\n",
    "net_worths = pickle.load( open(\"practice_outliers_net_worths.pkl\", \"r\") )\n",
    "\n",
    "### ages and net_worths need to be reshaped into 2D numpy arrays\n",
    "### second argument of reshape command is a tuple of integers: (n_rows, n_columns)\n",
    "### by convention, n_rows is the number of data points\n",
    "### and n_columns is the number of features\n",
    "ages       = numpy.reshape( numpy.array(ages), (len(ages), 1))\n",
    "net_worths = numpy.reshape( numpy.array(net_worths), (len(net_worths), 1))\n",
    "from sklearn.cross_validation import train_test_split\n",
    "ages_train, ages_test, net_worths_train, net_worths_test = train_test_split(ages, net_worths, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "### fill in a regression here!  Name the regression object reg so that\n",
    "### the plotting code below works, and you can see what your regression looks like\n",
    "\n",
    "\n",
    "try:\n",
    "    plt.plot(ages, reg.predict(ages), color=\"blue\")\n",
    "except NameError:\n",
    "    pass\n",
    "plt.scatter(ages, net_worths)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### identify and remove the most outlier-y points\n",
    "cleaned_data = []\n",
    "try:\n",
    "    predictions = reg.predict(ages_train)\n",
    "    cleaned_data = outlierCleaner( predictions, ages_train, net_worths_train )\n",
    "except NameError:\n",
    "    print \"your regression object doesn't exist, or isn't name reg\"\n",
    "    print \"can't make predictions to use in identifying outliers\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### only run this code if cleaned_data is returning data\n",
    "if len(cleaned_data) > 0:\n",
    "    ages, net_worths, errors = zip(*cleaned_data)\n",
    "    ages       = numpy.reshape( numpy.array(ages), (len(ages), 1))\n",
    "    net_worths = numpy.reshape( numpy.array(net_worths), (len(net_worths), 1))\n",
    "\n",
    "    ### refit your cleaned data!\n",
    "    try:\n",
    "        reg.fit(ages, net_worths)\n",
    "        plt.plot(ages, reg.predict(ages), color=\"blue\")\n",
    "    except NameError:\n",
    "        print \"you don't seem to have regression imported/created,\"\n",
    "        print \"   or else your regression object isn't named reg\"\n",
    "        print \"   either way, only draw the scatter plot of the cleaned data\"\n",
    "    plt.scatter(ages, net_worths)\n",
    "    plt.xlabel(\"ages\")\n",
    "    plt.ylabel(\"net worths\")\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print \"outlierCleaner() is returning an empty list, no refitting to be done\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope:  [ 5.07793064]\n",
      "Intercept:  [ 25.21002327]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "what slope does your regression have?\n",
    "\"\"\"\n",
    "# ages_train, ages_test, net_worths_train, net_worths_test = train_test_split(ages, net_worths, test_size=0.1, random_state=42)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(ages_train, net_worths_train)\n",
    "\n",
    "print 'Slope: ', reg.coef_[0]\n",
    "print 'Intercept: ', reg.intercept_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r-squared score:  0.878262478835\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "What is the score you get when using your regression to make predictions with the test data?\n",
    "\"\"\"\n",
    "print 'r-squared score: ', reg.score(ages_test, net_worths_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "returning 81 elements\n",
      "Slope:  [ 6.36859481]\n",
      "Intercept:  [-6.91861159]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "In outliers/outlier_cleaner.py, you will find the skeleton for a function called outlierCleaner() that you will fill in with a \n",
    "cleaning algorithm. It takes three arguments: predictions is a list of predicted targets that come from your regression, ages is \n",
    "the list of ages in the training set, and net_worths is the actual value of the net worths in the training set. There should be \n",
    "90 elements in each of these lists (because the training set has 90 points in it). Your job is to return a list called \n",
    "cleaned_data that has only 81 elements in it, which are the 81 training points where the predictions and the actual values \n",
    "(net_worths) have the smallest errors (90 * 0.9 = 81). The format of cleaned_data should be a list of tuples, where each tuple \n",
    "has the form (age, net_worth, error). \n",
    "\n",
    "Once this cleaning function is working, you should see the regression result changes. What is the new slope? Is it closer to the \n",
    "\"correct\" result of 6.25?\n",
    "\"\"\"\n",
    "def outlierCleaner(predictions, ages, net_worths):\n",
    "    \"\"\"\n",
    "        Clean away the 10% of points that have the largest\n",
    "        residual errors (difference between the prediction\n",
    "        and the actual net worth).\n",
    "\n",
    "        Return a list of tuples named cleaned_data where \n",
    "        each tuple is of the form (age, net_worth, error).\n",
    "    \"\"\"\n",
    "    cleaned_data = []\n",
    "    error = predictions - net_worths\n",
    "    diff = numpy.absolute(error)\n",
    "    elem = []\n",
    "    for k in zip(diff, ages, net_worths, error):\n",
    "        d, a, n, e = k\n",
    "        elem.append((d[0], a[0], n[0], e[0]))\n",
    "        \n",
    "    #calculate 10% of the ages\n",
    "    maxlen = len(ages)*0.1\n",
    "\n",
    "    for i, k in enumerate(sorted(elem, reverse=True)):\n",
    "        if i >= maxlen:\n",
    "            d, a, n, e = k\n",
    "            cleaned_data.append((a, n, e))\n",
    "    print 'returning %d elements' % len(cleaned_data)\n",
    "    return cleaned_data\n",
    "\n",
    "### identify and remove the most outlier-y points\n",
    "cleaned_data = []\n",
    "try:\n",
    "    predictions = reg.predict(ages_train)\n",
    "    cleaned_data = outlierCleaner( predictions, ages_train, net_worths_train )\n",
    "except NameError:\n",
    "    print \"your regression object doesn't exist, or isn't name reg\"\n",
    "    print \"can't make predictions to use in identifying outliers\"\n",
    "    \n",
    "    ### only run this code if cleaned_data is returning data\n",
    "    \n",
    "if len(cleaned_data) > 0:\n",
    "    ages, net_worths, errors = zip(*cleaned_data)\n",
    "    ages       = numpy.reshape( numpy.array(ages), (len(ages), 1))\n",
    "    net_worths = numpy.reshape( numpy.array(net_worths), (len(net_worths), 1))\n",
    "\n",
    "    ### refit your cleaned data!\n",
    "    try:\n",
    "        reg.fit(ages, net_worths)\n",
    "        plt.plot(ages, reg.predict(ages), color=\"blue\")\n",
    "    except NameError:\n",
    "        print \"you don't seem to have regression imported/created,\"\n",
    "        print \"   or else your regression object isn't named reg\"\n",
    "        print \"   either way, only draw the scatter plot of the cleaned data\"\n",
    "    plt.scatter(ages, net_worths)\n",
    "    plt.xlabel(\"ages\")\n",
    "    plt.ylabel(\"net worths\")\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print \"outlierCleaner() is returning an empty list, no refitting to be done\"\n",
    "\n",
    "print 'Slope: ', reg.coef_[0]\n",
    "print 'Intercept: ', reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r-squared score:  0.983189455686\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "What's the new score when you use the regression to make predictions on the test set?\n",
    "\"\"\"\n",
    "print 'r-squared score: ', reg.score(ages_test, net_worths_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In the mini-project for the regressions lesson, you used a regression to predict the bonuses for Enron employees. As you saw, \n",
    "even a single outlier can make a big difference on the regression result. There was something we didn't tell you, though, which \n",
    "was that the dataset we had you use in that project had already been cleaned of some significant outliers. Identifying and \n",
    "cleaning away outliers is something you should always think about when looking at a dataset for the first time, and now you'll \n",
    "get some hands-on experience with the Enron data.\n",
    "\n",
    "You can find the starter code in outliers/enron_outliers.py, which reads in the data (in dictionary form) and converts it into a \n",
    "sklearn-ready numpy array. Since there are two features being extracted from the dictionary (\"salary\" and \"bonus\"), the resulting \n",
    "numpy array will be of dimension N x 2, where N is the number of data points and 2 is the number of features. This is perfect input \n",
    "for a scatterplot; we'll use the matplotlib.pyplot module to make that plot. (We've been using pyplot for all the visualizations \n",
    "in this course.) Add these lines to the bottom of the script to make your scatterplot:\n",
    "\n",
    "for point in data:\n",
    "    salary = point[0]\n",
    "    bonus = point[1]\n",
    "    matplotlib.pyplot.scatter( salary, bonus )\n",
    "\n",
    "matplotlib.pyplot.xlabel(\"salary\")\n",
    "matplotlib.pyplot.ylabel(\"bonus\")\n",
    "matplotlib.pyplot.show()\n",
    "\n",
    "As you can see, visualization is one of the most powerful tools for finding outliers!\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "feature_format.py\n",
    "\"\"\"\n",
    "#!/usr/bin/python\n",
    "\n",
    "\"\"\" \n",
    "    A general tool for converting data from the\n",
    "    dictionary format to an (n x k) python list that's \n",
    "    ready for training an sklearn algorithm\n",
    "\n",
    "    n--no. of key-value pairs in dictonary\n",
    "    k--no. of features being extracted\n",
    "\n",
    "    dictionary keys are names of persons in dataset\n",
    "    dictionary values are dictionaries, where each\n",
    "        key-value pair in the dict is the name\n",
    "        of a feature, and its value for that person\n",
    "\n",
    "    In addition to converting a dictionary to a numpy \n",
    "    array, you may want to separate the labels from the\n",
    "    features--this is what targetFeatureSplit is for\n",
    "\n",
    "    so, if you want to have the poi label as the target,\n",
    "    and the features you want to use are the person's\n",
    "    salary and bonus, here's what you would do:\n",
    "\n",
    "    feature_list = [\"poi\", \"salary\", \"bonus\"] \n",
    "    data_array = featureFormat( data_dictionary, feature_list )\n",
    "    label, features = targetFeatureSplit(data_array)\n",
    "\n",
    "    the line above (targetFeatureSplit) assumes that the\n",
    "    label is the _first_ item in feature_list--very important\n",
    "    that poi is listed first!\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "def featureFormat( dictionary, features, remove_NaN=True, remove_all_zeroes=True, remove_any_zeroes=False, sort_keys = False):\n",
    "    \"\"\" convert dictionary to numpy array of features\n",
    "        remove_NaN = True will convert \"NaN\" string to 0.0\n",
    "        remove_all_zeroes = True will omit any data points for which\n",
    "            all the features you seek are 0.0\n",
    "        remove_any_zeroes = True will omit any data points for which\n",
    "            any of the features you seek are 0.0\n",
    "        sort_keys = True sorts keys by alphabetical order. Setting the value as\n",
    "            a string opens the corresponding pickle file with a preset key\n",
    "            order (this is used for Python 3 compatibility, and sort_keys\n",
    "            should be left as False for the course mini-projects).\n",
    "        NOTE: first feature is assumed to be 'poi' and is not checked for\n",
    "            removal for zero or missing values.\n",
    "    \"\"\"\n",
    "\n",
    "    return_list = []\n",
    "\n",
    "    # Key order - first branch is for Python 3 compatibility on mini-projects,\n",
    "    # second branch is for compatibility on final project.\n",
    "    if isinstance(sort_keys, str):\n",
    "        import pickle\n",
    "        keys = pickle.load(open(sort_keys, \"rb\"))\n",
    "    elif sort_keys:\n",
    "        keys = sorted(dictionary.keys())\n",
    "    else:\n",
    "        keys = dictionary.keys()\n",
    "\n",
    "    for key in keys:\n",
    "        tmp_list = []\n",
    "        for feature in features:\n",
    "            try:\n",
    "                dictionary[key][feature]\n",
    "            except KeyError:\n",
    "                print \"error: key \", feature, \" not present\"\n",
    "                return\n",
    "            value = dictionary[key][feature]\n",
    "            if value==\"NaN\" and remove_NaN:\n",
    "                value = 0\n",
    "            tmp_list.append( float(value) )\n",
    "\n",
    "        # Logic for deciding whether or not to add the data point.\n",
    "        append = True\n",
    "        # exclude 'poi' class as criteria.\n",
    "        if features[0] == 'poi':\n",
    "            test_list = tmp_list[1:]\n",
    "        else:\n",
    "            test_list = tmp_list\n",
    "        ### if all features are zero and you want to remove\n",
    "        ### data points that are all zero, do that here\n",
    "        if remove_all_zeroes:\n",
    "            append = False\n",
    "            for item in test_list:\n",
    "                if item != 0 and item != \"NaN\":\n",
    "                    append = True\n",
    "                    break\n",
    "        ### if any features for a given data point are zero\n",
    "        ### and you want to remove data points with any zeroes,\n",
    "        ### handle that here\n",
    "        if remove_any_zeroes:\n",
    "            if 0 in test_list or \"NaN\" in test_list:\n",
    "                append = False\n",
    "        ### Append the data point if flagged for addition.\n",
    "        if append:\n",
    "            return_list.append( np.array(tmp_list) )\n",
    "\n",
    "    return np.array(return_list)\n",
    "\n",
    "\n",
    "def targetFeatureSplit( data ):\n",
    "    \"\"\" \n",
    "        given a numpy array like the one returned from\n",
    "        featureFormat, separate out the first feature\n",
    "        and put it into its own list (this should be the \n",
    "        quantity you want to predict)\n",
    "\n",
    "        return targets and features as separate lists\n",
    "\n",
    "        (sklearn can generally handle both lists and numpy arrays as \n",
    "        input formats when training/predicting)\n",
    "    \"\"\"\n",
    "    target = []\n",
    "    features = []\n",
    "    for item in data:\n",
    "        target.append( item[0] )\n",
    "        features.append( item[1:] )\n",
    "\n",
    "    return target, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "enron_outliers.py\n",
    "\"\"\"\n",
    "#!/usr/bin/python\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "import matplotlib.pyplot\n",
    "#sys.path.append(\"../tools/\")\n",
    "#from feature_format import featureFormat, targetFeatureSplit\n",
    "\n",
    "### read in data dictionary, convert to numpy array\n",
    "data_dict = pickle.load( open(\"final_project_dataset.pkl\", \"r\") )\n",
    "features = [\"salary\", \"bonus\"]\n",
    "data = featureFormat(data_dict, features)\n",
    "\n",
    "for point in data:\n",
    "    salary = point[0]\n",
    "    bonus = point[1]\n",
    "    matplotlib.pyplot.scatter( salary, bonus )\n",
    "\n",
    "matplotlib.pyplot.xlabel(\"salary\")\n",
    "matplotlib.pyplot.ylabel(\"bonus\")\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:  TOTAL\n",
      "Salary:  26704229.0\n",
      "Bonus:  97343619.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "There's one outlier that should pop out to you immediately. Now the question is to identify the source. We found the original \n",
    "data source to be very helpful for this identification; you can find that PDF in final_project/enron61702insiderpay.pdf \n",
    "What's the name of the dictionary key of this data point? (e.g. if this is Ken Lay, the answer would be \"LAY KENNETH L\").\n",
    "\"\"\"\n",
    "maxsalary, maxbonus = numpy.nanmax(data, axis=0)\n",
    "for name in data_dict:\n",
    "    if data_dict[name]['salary'] == maxsalary and data_dict[name]['bonus'] == maxbonus:\n",
    "        print 'Name: ', name \n",
    "        print 'Salary: ', maxsalary\n",
    "        print 'Bonus: ', maxbonus\n",
    "# >>>print data_dict[0]\n",
    "# 'METTS MARK': {\n",
    "#                'salary': 365788, \n",
    "#                'to_messages': 807, \n",
    "#                'deferral_payments': 'NaN', \n",
    "#                'total_payments': 1061827, \n",
    "#                'exercised_stock_options': 'NaN', \n",
    "#                'bonus': 600000, \n",
    "#                'restricted_stock': 585062, \n",
    "#                'shared_receipt_with_poi': 702, \n",
    "#                'restricted_stock_deferred': 'NaN', \n",
    "#                'total_stock_value': 585062, \n",
    "#                'expenses': 94299, \n",
    "#                'loan_advances': 'NaN', \n",
    "#                'from_messages': 29, \n",
    "#                'other': 1740, \n",
    "#                'from_this_person_to_poi': 1, \n",
    "#                'poi': False, \n",
    "#                'director_fees': 'NaN', \n",
    "#                'deferred_income': 'NaN', \n",
    "#                'long_term_incentive': 'NaN', \n",
    "#                'email_address': 'mark.metts@enron.com', \n",
    "#                'from_poi_to_this_person': 38\n",
    "#               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A quick way to remove a key-value pair from a dictionary is the following line: dictionary.pop( key, 0 ) Write a line like this \n",
    "(you'll have to modify the dictionary and key names, of course) and remove the outlier before calling featureFormat(). Now rerun \n",
    "the code, so your scatterplot doesn't have this outlier anymore. Are all the outliers gone?\n",
    "\"\"\"\n",
    "data_dict.pop('TOTAL', 0)\n",
    "features = [\"salary\", \"bonus\"]\n",
    "data = featureFormat(data_dict, features)\n",
    "\n",
    "for point in data:\n",
    "    salary = point[0]\n",
    "    bonus = point[1]\n",
    "    matplotlib.pyplot.scatter( salary, bonus )\n",
    "\n",
    "matplotlib.pyplot.xlabel(\"salary\")\n",
    "matplotlib.pyplot.ylabel(\"bonus\")\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: LAY KENNETH L :: Salary: 1072321.000000 :: Bonus: 7000000.000000\n",
      "Name: SKILLING JEFFREY K :: Salary: 1111258.000000 :: Bonus: 5600000.000000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We would argue that there's 4 more outliers to investigate; let's look at a couple of them. Two people made bonuses of at least \n",
    "5 million dollars, and a salary of over 1 million dollars; in other words, they made out like bandits. What are the names \n",
    "associated with those points?\n",
    "\"\"\"\n",
    "for name in data_dict:\n",
    "    salary = data_dict[name]['salary']\n",
    "    bonus = data_dict[name]['bonus']\n",
    "    if salary != 'NaN' and bonus != 'NaN' and (salary > 1000000 and bonus > 5000000):\n",
    "        print 'Name: %s :: Salary: %f :: Bonus: %f' % (name, salary, bonus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
