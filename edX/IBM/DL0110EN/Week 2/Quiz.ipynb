{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prediction in One Dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What's wrong with the following class or custom module:<br>\n",
    "\n",
    "```\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(1)\n",
    "class LR(nn.Module):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        #super(LR, self).__init__()\n",
    "        nn.Module.__init__(self)\n",
    "        linear = nn.Linear(in_size, out_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "```\n",
    "\n",
    "&#9744; \"`super`\" is not needed<br>\n",
    "&#9744; \"`nn.Module`\" is not required<br>\n",
    "&#9745; \"`linear`\" should be `self.linear`<br>\n",
    "&#9744; The code will run fine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LR' object has no attribute 'linear'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a86849235ea3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/roger/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-a86849235ea3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/roger/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 518\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LR' object has no attribute 'linear'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LR(nn.Module):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        #super(LR, self).__init__()\n",
    "        nn.Module.__init__(self)\n",
    "        linear = nn.Linear(in_size, out_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "    \n",
    "# testing\n",
    "model = LR(1, 1)\n",
    "x = torch.tensor([[0.0]])\n",
    "y_ = model(x)\n",
    "print y_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Consider the following lines of code. How many Parameters does the object model have?<br>\n",
    "`from torch.nn import Linear`<br>\n",
    "`model=Linear(in_features=1,out_features=1)`<br>\n",
    "\n",
    "&#9744; 1<br>\n",
    "&#9745; 2<br>\n",
    "&#9744; 3<br>\n",
    "&#9744; None of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[0.6337]], requires_grad=True), Parameter containing:\n",
      "tensor([0.6783], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Linear \n",
    "model = Linear(in_features=1, out_features=1)\n",
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Linear Regression Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For linear regression, what is the assumption about the noise?<br>\n",
    "&#9745; It is Gaussian noise<br>\n",
    "&#9744; It is Laplacian noise<br>\n",
    "&#9744; It has zero variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. We obtain model parameters via:<br>\n",
    "&#9744; Testing<br>\n",
    "&#9744; Prediction<br>\n",
    "&#9745; Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The loss is a function of your:<br>\n",
    "&#9744; Data<br>\n",
    "&#9744; Noise<br>\n",
    "&#9745; Model Parameters<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The following is an example of:<br>\n",
    " <img src=\"images/quiz_loss.png\" width=\"30%\"/>\n",
    "\n",
    "&#9744; \"`w`\" space<br>\n",
    "&#9744; Data space<br>\n",
    "&#9745; Parameter space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In gradient descent, what happens when you select a learning rate that is too large?<br>\n",
    "&#9745; You may miss the minimum and your loss will start increasing<br>\n",
    "&#9744; It may take to long to converge to a minimum<br>\n",
    "&#9744; The loss function will become concave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. How do you select an initial parameter value for the first iteration of gradient descent?<br>\n",
    "&#9744; Set it to 100<br>\n",
    "&#9744; It should always be 0<br>\n",
    "&#9745; Randomly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For linear regression, what is true about the cost? (select all that apply)<br>\n",
    "&#9745; It is the sum or average of loss<br>\n",
    "&#9745; It is a measure of how well your model can predict the data<br>\n",
    "&#9745; It is a function of the slope and bias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Gradient Descent is sometimes referred to as Batch Gradient Descent?<br>\n",
    "&#9744; False<br>\n",
    "&#9745; True "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Training Parameters in PyTorch the Hard Way\n",
    "\n",
    "1. Your loss is a fuction of `w`. What method will calculate or accumulate gradients of your loss?<br>\n",
    "&#9744; w.grad<br>\n",
    "&#9745; loss.backward()<br>\n",
    "&#9744; loss.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Consider the derivative of the loss with respect to `w`, where `l` represents the value of the loss. How do you obtain the equivalent value in PyTorch?<br>\n",
    "\n",
    "$\\frac{dl(w=-10)}{dw}$\n",
    "\n",
    "&#9744; loss<br>\n",
    "&#9744; loss.backward()<br>\n",
    "&#9744; loss.grad<br>\n",
    "&#9745; w.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Training with Slope and Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Your loss is a function of `w` and `b`. What method will calculate or accumulate gradients of your loss?<br>\n",
    "&#9744; w.grad<br>\n",
    "&#9745; loss.backward()<br>\n",
    "&#9744; b.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The loss is a function of `w` and `b`. What is wrong with the following lines of code?\n",
    "\n",
    "`w.data = w.data - lr*w.grad.data`<br>\n",
    "`b.data = b.data - lr*b.grad.data`<br>\n",
    "`loss.backward()`<br>\n",
    "\n",
    "&#9744; `b.data` is not an attribute<br>\n",
    "&#9744; `w.data` is not an attribute<br>\n",
    "&#9745; You need to call `loss.backward()` before you have access to the gradient of `w` and `b`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How many samples at a time do you use for stochastic gradient descent?<br>\n",
    "Answer: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What is correct about stochastic gradient descent? (select all that apply)<br>\n",
    "\n",
    "&#9744; The loss must be linear<br>\n",
    "&#9745; The loss may exhibit sudden increases<br>\n",
    "&#9745; It's an approximation of batch gradient descent<br>\n",
    "&#9744; It always works better than batch gradient descent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Mini-Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. You have 100 samples of data and your batch size is 25. How many iterations will it take to go through 1 epoch?<br>\n",
    "Answer: 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the dataset class `Data()`. How would you create a data loader object `trainloader` with a batch size of 3?\n",
    "\n",
    "&#9744; `data_set=Data(batch_size=3)\n",
    "  trainloader=DataLoader(dataset=data_set)`<br><br>\n",
    "&#9745; `data_set=Data()\n",
    "  trainloader=DataLoader(dataset=data_set,batch_size=3)`<br><br>\n",
    "&#9744; `trainloader=Data(batch_size=3)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. PyTorch Way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What does the followling line of code do?<br>\n",
    "`optimizer.step()`<br>\n",
    "\n",
    "&#9744; Clears the gradient<br>\n",
    "&#9744; Computes the gradient of the loss with respect to all the learnable parameters<br>\n",
    "&#9744; Makes a prediction<br>\n",
    "&#9745; Makes an update to its parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What's missing from the following code?<br>\n",
    "\n",
    "`yhat=model(x)`<br>\n",
    "`loss=criterion(yhat,y)`<br>\n",
    "`loss.backward()`<br>\n",
    "`optimizer.step()`<br>\n",
    " \n",
    "&#9744; There is no prediction<br>\n",
    "&#9744; Calculation of the loss<br>\n",
    "&#9745; Does not clear the gradient<br>\n",
    "&#9744; There is no Backward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. What's wrong with the following lines of code?<br>\n",
    "\n",
    "`optimizer = optim.SGD(model.parameters(), lr = 0.01)`<br>\n",
    "`model=linear_regression(1,1)`\n",
    " \n",
    "&#9745; The model object has not been created. As such, the argument that specifies what Tensors should be optimized does not exist<br>\n",
    "&#9744; There is no loss function<br>\n",
    "&#9744; You have to clear the gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Training and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Training data is used to train the model; validation data is used to obtain what?<br>\n",
    "\n",
    "&#9745; Hyperparameters<br>\n",
    "&#9744; A test of how good the model performs in the real world<br>\n",
    "&#9744; The reduced model variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. For linear regression what are the Hyperparameters? (select all that apply)<br>\n",
    "\n",
    "&#9745; Bach size<br>\n",
    "&#9744; Slope<br>\n",
    "&#9744; Bias<br>\n",
    "&#9745; Learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What does the following line of code do?<br>\n",
    "\n",
    "`torch.save(model.state_dict(), 'best_model.pt')`\n",
    "\n",
    "&#9745; Saves the parameters of the model object so that you can use them later<br>\n",
    "&#9744; Saves your data<br>\n",
    "&#9744; Loads your model parameters<br>\n",
    "&#9744; Saves a PyTorch tensor as a .csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Early stopping uses the following to determine when to save the data:<br>\n",
    "    \n",
    "&#9744; Cost on the test data<br>\n",
    "&#9744; Number of iterations<br>\n",
    "&#9745; Cost on the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "&#9744;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
